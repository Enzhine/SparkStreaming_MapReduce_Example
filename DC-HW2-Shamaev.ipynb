{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51a92df6ec7b746f",
   "metadata": {},
   "source": [
    "# Распределенные вычисления ДЗ-2 | Шамаев Онар Евгеньевич "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7db5f2c875c41a",
   "metadata": {},
   "source": [
    "## Постановка задачи\n",
    "\n",
    "Необходимо в потоковом формате считывать последнюю активность сообщества r/AskReddit платформы Reddit.\n",
    "Целью будет найти самые встречающиеся слова.\n",
    "Необходимо использовать Spark Streaming сохраняя данные на HDFS.\n",
    "\n",
    "## План\n",
    "1. Создание TCP сервера (RSS читателя заголовков)\n",
    "2. Запуск HDFS\n",
    "3. Написать пайплайн Spark Streaming с окном обработки\n",
    "4. Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed36cf5044f39634",
   "metadata": {},
   "source": [
    "## 1. Создание TCP сервера (RSS читателя заголовков)\n",
    "\n",
    "Идея технологии RSS заключается в том, чтобы предоставлять последние N текстовых информативных блоков чего-либо. Например на новостных сайтах - это краткая сводка о последних события. В случае Reddit - это список последних назвний последних тем, поднимаемых пользователями в сообществе r/AskReddit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59edecd3c69378db",
   "metadata": {},
   "source": [
    "_Импорты библиотек._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c187257be5d4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import socket\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee44f67fa79f7eb7",
   "metadata": {},
   "source": [
    "Последние новости (в RSS формате) доступны по ссылке:\n",
    "`https://www.reddit.com/r/AskReddit/new/.rss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c96c2e9463f890",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:35:29.320248Z",
     "start_time": "2025-03-07T23:35:29.316579Z"
    }
   },
   "outputs": [],
   "source": [
    "rss_link = 'https://www.reddit.com/r/AskReddit/new/.rss'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebb3a1a7b5567a7",
   "metadata": {},
   "source": [
    "Определим программу читателя новостной ленты RSS и извлекающей оттуда заголовки, создающий TCP сокет и отправляющий их туда."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:35:31.290957Z",
     "start_time": "2025-03-07T23:35:31.284047Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding = 'utf-8'\n",
    "\n",
    "\n",
    "def rss2tcp_reader(ip, port, interval_sec: float = 30.0, ttl=None):\n",
    "    last_stamp: time.struct_time | None = None\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    s.bind((ip, port))\n",
    "    s.listen(1)\n",
    "\n",
    "    print(f'Awaiting connection at {ip}:{port}...')\n",
    "    conn, addr = s.accept()\n",
    "    print('Connected by ', addr)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            if (ttl is not None) and last_stamp > ttl:\n",
    "                print('Time to live passed. Exiting.')\n",
    "                break\n",
    "\n",
    "            feed = feedparser.parse(rss_link)\n",
    "            if feed.status != 200:\n",
    "                print(f'Bad response {feed.status} received! Exiting.')\n",
    "                break\n",
    "\n",
    "            _mx_stmp = None\n",
    "            for i, entry in enumerate(feed.entries):\n",
    "                title = entry.title\n",
    "                time_stamp = entry.published_parsed\n",
    "\n",
    "                if (last_stamp is None) or (last_stamp < time_stamp):\n",
    "                    if _mx_stmp is None: _mx_stmp = time_stamp\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "                conn.send(title.encode(encoding) + b'\\n')\n",
    "            if _mx_stmp is not None:\n",
    "                last_stamp = _mx_stmp\n",
    "\n",
    "            time.sleep(interval_sec)\n",
    "    except Exception as ex:\n",
    "        print(f'Exception happened {ex}')\n",
    "    finally:\n",
    "        s.close()\n",
    "        print(f'Closed connection')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977904fc9140cece",
   "metadata": {},
   "source": [
    "Данная программа представлена отдельно в файле `tcp_server.py`. Запустим ее независмо, чтобы можно было запускать ячейки ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd598312c1dbb54",
   "metadata": {},
   "source": [
    "## 2. Запуск HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1b92c7bdd23410",
   "metadata": {},
   "source": [
    "Воспользуемся наработками 1 дз. Поднимем HDFS кластер из 1 namenode и 2 datanode с помощью Docker.\n",
    "\n",
    "Запустим кластер из папки `compose` командой `docker-compose -f \"docker.compose.yml\" up -d`.\n",
    "\n",
    "UI кластера доступен по адресу `http://localhost:9870/`.\n",
    "\n",
    "Сама HDFS доступна по адресу `hdfs://localhost:8020`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c895aa2a86aec70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:35:37.881064Z",
     "start_time": "2025-03-07T23:35:37.878176Z"
    }
   },
   "outputs": [],
   "source": [
    "hdfs = 'hdfs://localhost:8020'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41eee99e9b48e03",
   "metadata": {},
   "source": [
    "## 3. Написать пайплайн Spark Streaming с окном обработки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e242cd821b967efc",
   "metadata": {},
   "source": [
    "_Импорты библиотек._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a432bd927b9c64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:35:44.242264Z",
     "start_time": "2025-03-07T23:35:43.422350Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "import os\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = 'python'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd59f7a4c2105a4",
   "metadata": {},
   "source": [
    "Создадим Спарк-контекст и Стриминговый контекст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "481b085bab7138fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:36:04.236625Z",
     "start_time": "2025-03-07T23:35:46.463067Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 57241)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Enzhine\\miniconda3\\envs\\sparked\\Lib\\socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"C:\\Users\\Enzhine\\miniconda3\\envs\\sparked\\Lib\\socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"C:\\Users\\Enzhine\\miniconda3\\envs\\sparked\\Lib\\socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"C:\\Users\\Enzhine\\miniconda3\\envs\\sparked\\Lib\\socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"C:\\Users\\Enzhine\\miniconda3\\envs\\sparked\\Lib\\site-packages\\pyspark\\accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"C:\\Users\\Enzhine\\miniconda3\\envs\\sparked\\Lib\\site-packages\\pyspark\\accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"C:\\Users\\Enzhine\\miniconda3\\envs\\sparked\\Lib\\site-packages\\pyspark\\accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Enzhine\\miniconda3\\envs\\sparked\\Lib\\site-packages\\pyspark\\serializers.py\", line 594, in read_int\n",
      "    length = stream.read(4)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Enzhine\\miniconda3\\envs\\sparked\\Lib\\socket.py\", line 718, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "ctx = SparkContext(master=\"local[2]\", appName=\"AskRedditWordCounter\")\n",
    "ctx._jsc.hadoopConfiguration().set('dfs.client.use.datanode.hostname', 'true')\n",
    "\n",
    "spark = SparkSession(ctx)\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11c642ae033e0d0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:36:06.833515Z",
     "start_time": "2025-03-07T23:36:06.785452Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Enzhine\\miniconda3\\envs\\sparked\\Lib\\site-packages\\pyspark\\streaming\\context.py:72: FutureWarning: DStream is deprecated as of Spark 3.4.0. Migrate to Structured Streaming.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling store at 2025-03-14 03:45:20\n",
      "set top to ['what', 'you', 'the', 'is', 'and'] at 2025-03-14 03:45:20\n",
      "handling store at 2025-03-14 03:45:50\n",
      "set top to ['you', 'what', 'your', 'the', 'would'] at 2025-03-14 03:45:50\n",
      "handling store at 2025-03-14 03:46:20\n",
      "storing\n",
      "set top to ['you', 'a', 'of', 'that', 'what'] at 2025-03-14 03:46:20\n",
      "handling store at 2025-03-14 03:46:50\n",
      "storing\n",
      "set top to ['what', 'a', 'your', 'the', 'to'] at 2025-03-14 03:46:50\n",
      "handling store at 2025-03-14 03:47:20\n",
      "storing\n",
      "set top to ['you', 'what', 'to', 'the', 'of'] at 2025-03-14 03:47:20\n",
      "handling store at 2025-03-14 03:47:50\n",
      "storing\n",
      "set top to ['you', 'what', 'the', 'do', 'in'] at 2025-03-14 03:47:50\n",
      "handling store at 2025-03-14 03:48:20\n",
      "storing\n",
      "set top to ['you', 'what', 'your', 'the', 'would'] at 2025-03-14 03:48:20\n",
      "handling store at 2025-03-14 03:48:50\n",
      "storing\n",
      "set top to ['what', 'you', 'your', 'the', 'a'] at 2025-03-14 03:48:50\n",
      "handling store at 2025-03-14 03:49:20\n",
      "storing\n",
      "set top to ['you', 'the', 'what', 'how', 'in'] at 2025-03-14 03:49:20\n",
      "handling store at 2025-03-14 03:49:50\n",
      "storing\n",
      "set top to ['what', 'you', 'the', 'to', 'do'] at 2025-03-14 03:49:50\n",
      "handling store at 2025-03-14 03:50:20\n",
      "storing\n",
      "set top to ['you', 'the', 'what', 'of', 'would'] at 2025-03-14 03:50:20\n",
      "handling store at 2025-03-14 03:50:50\n",
      "storing\n",
      "set top to ['you', 'what', 'the', 'to', 'a'] at 2025-03-14 03:50:50\n",
      "handling store at 2025-03-14 03:51:20\n",
      "storing\n",
      "set top to ['you', 'what', 'the', 'your', 'to'] at 2025-03-14 03:51:20\n",
      "handling store at 2025-03-14 03:51:50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Enzhine\\miniconda3\\envs\\sparked\\Lib\\site-packages\\py4j\\clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Enzhine\\miniconda3\\envs\\sparked\\Lib\\socket.py\", line 718, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Enzhine\\miniconda3\\envs\\sparked\\Lib\\site-packages\\py4j\\java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Enzhine\\miniconda3\\envs\\sparked\\Lib\\site-packages\\py4j\\clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Enzhine\\miniconda3\\envs\\sparked\\Lib\\site-packages\\py4j\\clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Enzhine\\miniconda3\\envs\\sparked\\Lib\\socket.py\", line 718, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Enzhine\\miniconda3\\envs\\sparked\\Lib\\site-packages\\py4j\\java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Enzhine\\miniconda3\\envs\\sparked\\Lib\\site-packages\\py4j\\clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    }
   ],
   "source": [
    "ctx_stream = StreamingContext(ctx, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec2e864c9d2a548",
   "metadata": {},
   "source": [
    "PySpark UI доступен по адресу `http://localhost:4040`.\n",
    "\n",
    "Будем использовать DStream, считывающий данные по TCP соединению, созданном нашим RSS читателем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a146b0e741d29b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:36:15.117157Z",
     "start_time": "2025-03-07T23:36:15.074467Z"
    }
   },
   "outputs": [],
   "source": [
    "ip = 'localhost'\n",
    "port = 9999\n",
    "\n",
    "d_stream = ctx_stream.socketTextStream(ip, port)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82affc2efc435c8d",
   "metadata": {},
   "source": [
    "Определим фильтр, для подготовки к разбиению заголовков на слова, и непосредственно разделитель на слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c5adb4312582ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:36:17.722114Z",
     "start_time": "2025-03-07T23:36:17.717951Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "\n",
    "def prepare(line: str) -> str:\n",
    "    return line.translate({key: ' ' for key in string.punctuation + '?!()$@/'}).lower()\n",
    "\n",
    "\n",
    "def word_splitter(line: str) -> list[str]:\n",
    "    return filter(lambda w: len(w) != 0, line.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2080453a720bc6",
   "metadata": {},
   "source": [
    "Определим следующий пайплайн:\n",
    "1. У потока DStream берем производный поток DStream с окном в 30 секунд. Назовем его потоком заголовков.\n",
    "2. На поток заголовков поставим обработчики: фильтр всех закголовков, имеющих слова из топ-5 слов, и обработчик сохранения в HDFS заголовков.\n",
    "3. Сделаем новый производный поток трансформации заголовоков в пары (слово, количество), которые будут сортироваться по количеству в обратном порядке. После сортировки поставим обработчик: сохранения топ-5.\n",
    "\n",
    "Таким образом каждые 30 секунд, с некоторой фазой, переменная топ-5 заполнится актуальным топом. С интервалом в 30 секунд поток заголовков будет их фильтроват по топу и сохранять в HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "405b2884-422a-405b-bb2d-f3ad5c66a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_lines = d_stream.window(windowDuration=30, slideDuration=30)\n",
    "\n",
    "\n",
    "def store(time_, rdd):\n",
    "    print(f'handling store at {time_}')\n",
    "    if rdd.isEmpty():\n",
    "        return\n",
    "\n",
    "    print('storing')\n",
    "    df = rdd.map(lambda line: (line,)).toDF(schema=[\"titles\"])\n",
    "    df.write.format('json').mode('append').save(hdfs + '/reddit_titles.json')\n",
    "\n",
    "\n",
    "current_top = []\n",
    "\n",
    "\n",
    "def filter_by_top(line):\n",
    "    global current_top\n",
    "\n",
    "    print(f'checked {line} for contain of {current_top}')\n",
    "    return any(word in line for word in current_top)\n",
    "\n",
    "windowed_lines_cached = windowed_lines.transform(lambda rdd: rdd.filter(filter_by_top)).foreachRDD(store)\n",
    "\n",
    "\n",
    "def handle_top(time_, rdd):\n",
    "    global current_top\n",
    "    current_top = rdd.map(lambda pair: pair[0]).take(5)\n",
    "    print(f'set top to {current_top} at {time_}')\n",
    "\n",
    "\n",
    "windowed_lines.flatMap(lambda line: word_splitter(prepare(line))) \\\n",
    "    .map(lambda word: (word, 1)) \\\n",
    "    .reduceByKey(lambda x, y: x + y) \\\n",
    "    .transform(lambda rdd: rdd.sortBy(lambda x: -x[1])) \\\n",
    "    .foreachRDD(handle_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be61264-51b9-4255-89c1-cca98b0caaa6",
   "metadata": {},
   "source": [
    "Запустим джобу на 10 минут. Теперь она будет работать на фоне и собирать статистику встречаемых слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "603969914b3e94e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:38:35.951154Z",
     "start_time": "2025-03-07T23:36:35.862010Z"
    }
   },
   "outputs": [],
   "source": [
    "ctx_stream.start()\n",
    "ctx_stream.awaitTermination(10 * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6a7359-8f29-46d4-bd88-6ee77005bbda",
   "metadata": {},
   "source": [
    "_Импорты библиотек._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aec0f85c-7e38-44b7-806d-5dc3e1cf080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3604c685-a2dd-4d17-99a7-8a424e92c5cd",
   "metadata": {},
   "source": [
    "# 4. Результаты\n",
    "Вычитаем полученные заголовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a15d573-0c67-4e13-a07a-faebcd3a446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(hdfs + \"/reddit_titles.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1bbb9ba-466f-4b77-9490-f334973d02b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why when a male customer entered the store whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why when a male customer entered the store whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Women, you marry a man that supports you in yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Serious] US people serving in the armed force...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>People who were working during the 2008 recess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is your opinion of a school Parent Organi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Redditors that believe in \"high value men\" or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Have you or do you know anyone who's won a yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How has the level of stress in your life chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What would happen if there were an AI that cou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titles\n",
       "0  Why when a male customer entered the store whe...\n",
       "1  Why when a male customer entered the store whe...\n",
       "2  Women, you marry a man that supports you in yo...\n",
       "3  [Serious] US people serving in the armed force...\n",
       "4  People who were working during the 2008 recess...\n",
       "5  What is your opinion of a school Parent Organi...\n",
       "6  Redditors that believe in \"high value men\" or ...\n",
       "7  Have you or do you know anyone who's won a yea...\n",
       "8  How has the level of stress in your life chang...\n",
       "9  What would happen if there were an AI that cou..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df = df.toPandas()\n",
    "pandas_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
